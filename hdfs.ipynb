{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801e0104-0bac-4d71-b5c0-3567beb90496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 설치하기\n",
    "! pip install hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a24cb4b-adb7-4e8f-8704-382319701602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장\n",
    "import hdfs #1 \n",
    "import json\n",
    "# from hdfs import InsecureClient #2\n",
    "\n",
    "# psspark 스파크 = 실시간 데이터분석이 가능함.\n",
    "\n",
    "# 1. hdfs web으로 접속 (9870,9864,9000,9866)\n",
    "client_hdfs = hdfs.InsecureClient('http://1.234.5.158:9870', user='hdfs') #1\n",
    "# InsecureClient() #2\n",
    "\n",
    "# 2. 수집한 자료 [{}] (리스트(딕셔너리))\n",
    "data = [{'name':'가1','weight':1,'height':2},{'name':'가1','weight':1,'height':2}]\n",
    "\n",
    "\n",
    "# 3. 삭제하기\n",
    "# client_hdfs.delete('/id117/ex_20210524.json')\n",
    "\n",
    "# 4. 저장하기\n",
    "# with는 자원을 흭득하고 사용 후 반납하는 경우에 사용\n",
    "with client_hdfs.write('/id117/ex_20210525.json', encoding = 'utf-8') as writer:\n",
    "    json.dump(data,writer)\n",
    "    \n",
    "# 5. 확인 크롬에서 http://1.234.5.158:9870/explorer.html#/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc655af1-eb2c-40c2-92de-1baedecd948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 가져오기\n",
    "from hdfs import InsecureClient\n",
    "import pandas as pd\n",
    "\n",
    "client_hdfs = InsecureClient('http://1.234.5.158:9870', user='hdfs')\n",
    "\n",
    "# 파일 목록 확인\n",
    "print(client_hdfs.list('/id117')) \n",
    "\n",
    "with client_hdfs.read('/id117/ex_20210524.json', encoding='utf-8') as reader:\n",
    "    df = pd.read_json(reader)\n",
    "# df.loc[:,['name']] name만 출력\n",
    "df\n",
    "#     for tmp in reader:\n",
    "#         print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3680e346-7339-463a-a371-574b9abf24ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ff0dd1-7d46-4325-b9bc-d2b304e83261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import bs4 # pip install bs4\n",
    "import time\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "url = 'https://datalab.naver.com/shoppingInsight/sCategory.naver'\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(executable_path='driver/chromedriver.exe', options = options)\n",
    "driver.get(url) # 창이 열림\n",
    "\n",
    "time.sleep(1)\n",
    "response = driver.page_source\n",
    "# driver.close() # 창이 닫힘\n",
    "\n",
    "soup = bs4.BeautifulSoup(response,'html.parser')\n",
    "\n",
    "# for tmp in soup.select('#topRecomKeywordWrap > div.cont_item > ul > li > .tit_rank'):\n",
    "#     print(tmp.text)\n",
    "\n",
    "# find   == select_one\n",
    "# find_all  == select\n",
    "\n",
    "# data = [{},{},{},{}.. 20개 ]\n",
    "data2 = []\n",
    "data3 = []\n",
    "# arr = {}\n",
    "for idx, tmp in enumerate(soup.select('ul.rank_top1000_list > li')):\n",
    "    data2.append( {str(idx+1) : tmp.text.strip() } )\n",
    "    string = tmp.text.strip()\n",
    "    a = []\n",
    "    for i in string: # 문자열 반복문\n",
    "        if not i.isdigit(): # 숫자가 아니면\n",
    "            a.append(i)\n",
    "    newString = ''.join(a)\n",
    "    print(newString)\n",
    "    data3.append( {str(idx+1) : newString } )\n",
    "#     arr[str(idx)] = tmp.text.strip()\n",
    "\n",
    "print(data3)\n",
    "driver.close() #창이 닫힘\n",
    "\n",
    "\n",
    "# 1~20 까지 수집한 후 hdfs에 저장 datalab_naver_20210524.json로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e82c0-5616-476a-92f7-4bc04fa5a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장\n",
    "import hdfs #1 \n",
    "import json\n",
    "# from hdfs import InsecureClient #2\n",
    "\n",
    "# psspark 스파크 = 실시간 데이터분석이 가능함.\n",
    "\n",
    "# 1. hdfs web으로 접속 (9870,9864,9000,9866)\n",
    "client_hdfs = hdfs.InsecureClient('http://1.234.5.158:9870', user='hdfs') #1\n",
    "# InsecureClient() #2\n",
    "\n",
    "# 2. 수집한 자료 [{}] (리스트(딕셔너리))\n",
    "\n",
    "# 3. 삭제하기\n",
    "# client_hdfs.delete('/id117/ex_20210524.json')\n",
    "\n",
    "# 4. 저장하기\n",
    "# with는 자원을 흭득하고 사용 후 반납하는 경우에 사용\n",
    "with client_hdfs.write('/id117/ex_datalab_naver_20210526.json', encoding = 'utf-8') as writer:\n",
    "    json.dump(data3,writer)\n",
    "    \n",
    "# 5. 확인 크롬에서 http://1.234.5.158:9870/explorer.html#/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd03412d-63f0-4dde-b77c-f46a56ab4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 가져오기\n",
    "from hdfs import InsecureClient\n",
    "import pandas as pd\n",
    "\n",
    "client_hdfs = InsecureClient('http://1.234.5.158:9870', user='hdfs')\n",
    "\n",
    "# 파일 목록 확인\n",
    "print(client_hdfs.list('/id117')) \n",
    "\n",
    "with client_hdfs.read('/id117/ex_datalab_naver_20210526.json', encoding='utf-8') as reader:\n",
    "    df = pd.read_json(reader)\n",
    "df\n",
    "# df.loc[:,['name']] name만 출력\n",
    "\n",
    "# for tmp in reader:\n",
    "#     print(tmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
